import re
def transcript_without_timestamps(transcript_string):
    # Split the string into lines
    lines = transcript_string.split('\n')
    
    # Initialize a list to store text without timestamps
    text_without_timestamps = []

    # Iterate through the lines and extract text only
    for line in lines:
        # Check if the line starts with a timestamp (e.g., "0:04") and skip it
        if not re.match(r'^\d+:\d+', line):
            text_without_timestamps.append(line.strip())

    # Join the text without timestamps into a single string
    transcript_text = "\n".join(text_without_timestamps)

    return transcript_text



text = """0:00
0:00
Jeremy welcome to the show thank you very much for having me excited to be here do you have a quote something that
0:05
inspires or motivates you that you can share with us well I've picked Jack Cousteau who is a
0:11
personal hero of mine for those who don't know a Jacques Cousteau is a famous French Ocean Explorer who did a
0:18
whole bunch of interesting underwater cinematography it is kind of the David Attenborough of underwater worlds B I
0:24
personally have a big obsession with marine life fish sharks whales dolphins animals squids crazy invertebrates
0:32
things like that so Jacques Cousteau is a real hero of mine and he said what is a scientist after all question mark it
0:40
is a curious person looking through a keyhole trying to know what's going on and I love that quote because
0:46
fundamentally that's what we do at a test we give people the ability to look through these keyholes to try to
0:52
understand what's going on to look through more keyholes to look with more granularity and to act like an Explorer
0:59
or an experimenter or scientist and it's Cousteau who says put on your uh put on
1:05
your diving mask and take a look through a tiny portal into the outside world underwater and discover piece by piece
1:11
what's going on and that's fundamentally how I feel about the world of consumer research take little looks into lots of
1:17
things and then again actually a unique picture that's very beautiful and valuable will unveil itself and Cousteau
1:23
tells us all about that and that's why I love that quote what a well thought out quote I love it all right let's talk
1:29
about a test so tell us what does the product do who's it for and what's the
1:34
main problem you're helping to solve so fundamentally a test makes doing high quality and Powerful research
1:41
ridiculously easy and accessible for anyone we like to use the phrase inform every intuition dissolve any doubt and
1:49
we use that phrase because we know that all b2c businesses that's our customers
1:54
our Target customers pretty much everyone in every BC businesses every b2c business wishes they knew more about
2:00
their Target customers they want to be more customer-centric they want to be more data driven they're just lacking a way to actually do it it's easy to look
2:07
at your CRM data it's easy to send emails or surveys to your existing customers understanding the customers
2:13
you don't have yet the barriers to them using your products the country you're not in the segment you're weak in the
2:19
competitor you don't get the product you've yet to launch making the choices accurately based on what consumers think
2:27
that's Alchemy that's goals that's the most valuable thing you get your hands on and that's the thing that we're trying to make a ridiculously easy
2:33
starting in 90 seconds we call it things like consumer research platform we say
2:38
that it makes it very easy to do very regular research all the time for anybody but deep down it's helping you
2:44
understand the customers you need to know the most but can reach the least because those consumers will choose who
2:50
wins or loses and decide whether you do or don't make your numbers this quarter and a test makes understanding them
2:57
ridiculously easy all the time and that's what we set out to build and that's what we do today so just in simple terms can you just explain how it
3:03
works how would somebody use a test yeah in the simplest terms you can show or
3:09
ask pretty much anything to over 125 million people in 58 countries starting
3:15
in 90 seconds as often as you want for any reason there tends to be a sort of top eight
3:22
set of reasons that different b2c companies use this product and it's things like internationalization
3:28
launching new products monitoring Trends over time figuring out what choice we should make next but every single thing
3:35
customers our customers use it for is completely unique and totally proprietary but fundamentally it makes
3:41
the end-to-end Journey of doing great research possible to start in 90 seconds and complete another 24 hours so the
3:47
business was founded in 2015. what were you doing at the time and how did you
3:53
come up with the idea I'll answer those both at the same time so originally I was a a scientist I
4:00
worked in genetics ecology mathematical modeling of animal behavior I published
4:05
some work on understanding how and why baby reef fish grow up and how they move
4:10
around and why they move to specific places using computer simulations of sounds and coral reefs and fish and
4:16
ability to swim and happy to send a link on that if that's interesting so I personally have a big love for
4:22
empiricism testing hypotheses using data to make decisions and following ideas
4:27
until you find something or nothing and then trying to link those things together like Cousteau with his keyholes
4:32
that's what I'm trained to do and that's how I believe the world should work I then spent nine years at McKinsey worked
4:39
in 25 different countries or more than that in all sorts of different sectors and I
4:44
found that isn't how businesses work I found rooms full of people guessing what consumers wanted people in Chicago
4:52
projecting what would work on product launches aimed at women in India none of
4:58
those people had a clue what was going on with women in India most of those people had never met any women in India and certainly had no data about them nor
5:04
had they tested what they wanted so I found everywhere I looked people were instead of using data and
5:10
experimentation they were using their own subjectivity guessing or just hope and as a scientist that made me angry
5:16
and as a McKinsey consultant that didn't make logical sense and didn't I couldn't
5:21
see a clear path to value a test basically links those two things together with the SAS business model and
5:27
then jumps on a very big opportunity in town so we make it really easy to do the
5:32
science thing for any company anywhere including me when I was an analyst or all those people I worked with who
5:38
should have been using great research but couldn't get it and then we put that together as a investment case and a sort of company
5:44
story market research is a 90 billion dollar total adjustable Market it only serves
5:51
in my view highly qualified dedicated professionals who mostly live in big companies but yet everybody in BC
5:58
businesses should do this all the time they're just lacking a way to actually do it so that Tam should be
6:04
10 to 50 times larger and if we can using SAS automation make a scalable
6:09
solution that people can actually just pick up and use and forget about how complex it is that would be a very
6:15
valuable thing to do that is also a thing that I care about personally that I've also seen in many places and the Genesis of a test came from putting
6:21
those three things together and then the very early prototypes of making a company out of it and some very strange
6:26
things I did to prove or disprove some of those hypotheses to myself okay great so you've got the idea what
6:33
kind of did you kind of take the McKinsey approach to kind of
6:39
scope out the opportunity here and and really do the research before you
6:46
started kind of jumping into building the product how did you get started very much so uh in that I did do the McKinsey
6:53
thing all the desktop research about the Tam the opportunity competitors strengths weaknesses Dynamics I was
6:59
looking for not only a large Tam but also some significant Tailwinds around
7:04
business model or funding sources customer needs the development of technology and also different scalable
7:11
methods that we could put in place to cause this thing to work bigger and faster and more scalably than doing a
7:17
sort of terrible quick and dirty version we sort of embarked to build the hard thing so I did all the desktop work to
7:23
discover roughly where to look what to build and what would have the greatest
7:28
chance of success with the most positive forces behind it and then paired that with some pretty
7:33
weird practical stuff so two stories here one before starting even
7:39
incorporating the company I went out and did some practical work second I tried to set up to Fast Track the first two
7:46
years of the company and compress that into about four to six months so on the
7:52
first one I had this hypothesis that most demand for research happens in the
7:57
corporate head office in a really important function in the org chart where all the data happens but everyone
8:04
in the org chart deep down really wants research everyone has questions everyone needs answers everyone wants to
8:09
understand consumers better and so the total demand is much higher so to prove that out I went to Waterloo Station I
8:16
used to live around the corner um during morning rush hours and afternoon rush hour and evening rush hours I went to
8:24
two stores on the upper balcony of Waterloo Station and said what do you wish you knew about your Target
8:30
customers in Waterloo Station that would be very valuable to you where you know nothing right now and out came this
8:37
flood of mystery Intrigue and guesswork they said okay and these two stores were
8:43
Keels skin care and links accessories and interesting corporate gifts
8:49
completely butchered what they're called by the way I don't even know what they do anymore so I went to the two store managers and they poured out all these
8:55
questions it was very clear that they had demand what was also interesting is that their questions remarkably consistent what's unique about Waterloo
9:03
Station and the customers that come through here and their needs that's different from what our two shops stand
9:08
for and the supply that we've got here what are the occasions people are buying for what stops them from coming upstairs do they even know we're here what should
9:16
we sell to them that we can offer that we don't put in the front window or prioritize our emphasize right now what
9:22
would get them to come upstairs what sort of offers do they have what occasions they're buying for this flood of demand came out I was like okay
9:28
interesting immediately these people who have no access to research have really valuable important questions and there's
9:34
a lot of consistency about their use cases so what I did was I promised these two store managers I'm going to physically
9:40
go out for each of you and interview 100 people each in Waterloo Station and ask
9:45
them your most valuable questions I'm going to tabulate that data I'm going to bring it back to you and I physically did that over the course of two weeks
9:52
and I tabulated the data took it back and they were like this is the most useful thing that's ever happened and I
9:58
think this will really help me and my store make better decisions about how we sell and serve these Waterloo customers
10:04
I've always thought deep down that these customers want something different from Keels or links than we set out to create
10:10
but yet head office don't let me do that here is some evidence that will cause me to do ranging differently to do
10:17
promotions differently to Market downstairs and suspend some Budget on that and I'll know roughly what the ROI
10:22
needs to be for the first time can I share this with head office can we do this again for other stations can I do
10:27
this in more places and countries and use cases and product lines and by the way we've got um Easter coming up what can we do about
10:34
that and so there was clearly hypothesis proven around more demand and hypothesis proven about everyone needs this not
10:41
just professionals doing research projects did you charge them for the work you were doing no no no I'm like
10:47
the value I was getting was um testing hypotheses for a test and also very early product prototypes
10:53
around what do you need to know and how do you want to receive the data so if anything I should have been paying them
10:58
so how did how did they react to you coming in like you know it kind of sounds like
11:04
you know a bit of a weirdo coming in saying asking these questions and saying I'm going to not just interview like 10 people for you I'm going to spend like
11:10
two weeks and 100 people and come back and do all of this work and you don't have to pay for it
11:17
um were they skeptical would they like what was the reaction I think that both
11:23
of them were deeply skeptical they were like who the hell is this guy and are you a mystery shopper have you been sent
11:29
here by firm legal to test our age security um and then I to I tried to keep two
11:34
motivations at heart so one is I try to be very disarming so I tried to basically say you know what's the worst
11:39
that can happen and tell me some of your biggest problems you don't need to tell me all your biggest problems but tell me the ones that you can actually learn
11:45
from consumers I don't need to know why I just need to know what you wish you knew that's the only thing I care about
11:50
and I will promise to come back to you on this day at this time and I'm going to ask you when you're on roster on
11:56
shift here and only converge that time and I will be here I think the second thing that worked to my favor is I think they both fundamentally believed that I
12:03
wasn't going to do it and they were like yeah yeah I'll believe it when I see it so when I did come back I think they were more shocked when I came back with
12:09
real data and was happy to talk through it for an hour and a half each than I was then they were shocked when I asked
12:15
in the first place so using both of those things to our advantage I always
12:20
like to think about interest alignment where are the where are the fears and where can how can we preclude them or
12:25
remove them and where are the interests around points of value and how can I align with them and both of those had a
12:31
fear of losing data or doing something wrong both of them had no belief I would come back so I tried to demonstrate to
12:36
them I would come back and then when I did come back I really followed through and made it valuable to them and actually went and did the work and that
12:43
helped melt away all these concerns and that's some of the tactics that we still use in our go to market today love it
12:48
love it but that's really like walking in the talk in terms of getting out of the building and and talking to
12:54
customers and you know I often talk to Founders who are reluctant to go out and talk to customers because they're like I
13:01
don't have a product yet I don't have something to show them well actually that's a great opportunity because you
13:07
you want you can spend the time talking about their problems asking them questions right you don't need to show
13:13
them anything and this is a really good example of that I'm impressed you managed to
13:18
stop 200 people in Waterloo Station and answer your questions because you know when I am you know when I was in London
13:23
walking through a train station and I saw a clipboard man I was like I
13:29
was making a detour to make sure that I wasn't going to get stopped with that conversation well it was there was one there was one particular thing that went
13:35
a bit wrong so one of one of the people I stopped uh she was very smartly dressed and she was clearly you know
13:42
attentively Waiting for a Train typing on her BlackBerry that's how long ago this was uh and it became very clear
13:48
after about 20 seconds that she was like who the bleep are you I was like okay this is unusual she was like I'm gonna
13:55
stop you do you have permission from links to uh to ask these questions I was like yeah I spoke to the store manager
14:01
upstairs name she was like that's very interesting because I'm actually I'm actually the area manager for
14:06
Southeastern London for Links of London the the parent company of that store and
14:12
I haven't authorized this um I was like well I'd love to know what you think about the problems with this store and
14:18
what do you think the opportunity is and by the way if you'd like to receive the data I'd love to send it your way she was like I would like to receive that
14:23
data thank you and I'd also like to know how useful to store manager is and I'll be following up on that it's not like well I'll be following up with you on
14:29
what you think about their perceptions to the value because this might be something you want to repeat so it
14:34
turned a very alarming moment into a potentially very high value one in about 10 seconds but there was a big surprise
14:40
there in 10 seconds where it could have gone either way and that was that was a bit spicy
14:46
all right so a lot of companies talk about you know we're a fast growing SAS company
14:52
you guys went from zero to First million in ARR in about what seven months
15:01
uh seven and a half months I think seven and a half months so tell me what how did you do that okay
"""





from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer

cleaned = transcript_without_timestamps(text)

# Create a plaintext parser
parser = PlaintextParser.from_string(cleaned, Tokenizer("english"))

# Create an LSA summarizer
summarizer = LsaSummarizer()

# Get a summary with a specified number of sentences (e.g., 3)
summary = summarizer(parser.document, 20)

# Print the summary sentences
for sentence in summary:
    tokens = sentence.words
    token_length = len(tokens)
    print(f"Sentence: - Token Length: {sentence}")


print(len(cleaned)), print(len(text)), print(len(summary))


print(cleaned)


import openai

# Set your API key
openai.api_key = "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"

# Initialize a variable to store the aggregated summary
aggregated_summary = ""
counter = 0
# Process each text chunk sequentially
for chunk in text_chunks:
    counter = counter+1
    # Create the prompt for the current chunk
    prompt = f"Summarize the following text as short and coherent as possible:\n{chunk}"

    # Send the prompt to ChatGPT
    response = openai.Completion.create(
        engine="text-davinci-003",
        prompt=prompt,
        max_tokens=500  # Adjust max_tokens based on your desired response length
    )

    # Extract the summarized text from the response
    summary = response.choices[0].text.strip()

    # Append the current summary to the accumulated summaries
    aggregated_summary += f"chunk {counter}:\n"+summary + "\n"

# Print the aggregated summary
print("Aggregated Summary:")
print(aggregated_summary)

